<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Categories: Algorithm | Learning Blog]]></title>
  <link href="http://fubuki.github.io/blog/categories/algorithm/atom.xml" rel="self"/>
  <link href="http://fubuki.github.io/"/>
  <updated>2014-08-17T23:43:54+08:00</updated>
  <id>http://fubuki.github.io/</id>
  <author>
    <name><![CDATA[Fubuki]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Boosting and Bagging]]></title>
    <link href="http://fubuki.github.io/blog/2014/08/08/boosting-and-bagging/"/>
    <updated>2014-08-08T23:28:16+08:00</updated>
    <id>http://fubuki.github.io/blog/2014/08/08/boosting-and-bagging</id>
    <content type="html"><![CDATA[<!-- more -->


<p>Ensemble learning (集成學習)，似乎是混合多個學習演算法提高結果的精確度 ，而 boosting 和 bagging便是
其中集成學習的兩種方法，下面整理一些學習資源。</p>

<h3>boosting</h3>

<p>AdaBoost（Adaptive Boosting）</p>

<p>使用同一個訓練集， 每次訓練的時候針對有問題訓練資料加大權重，讓函數靠往有問題的訊息資料。</p>

<h3>bagging</h3>

<p>每次訓練函數的時候從資料取出子資料集，然後多次訓練函數，最後有多個分類函數以投票方式分類新的資料。</p>

<h3>差別</h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[自然語言分類演算法]]></title>
    <link href="http://fubuki.github.io/blog/2014/08/08/zi-ran-yu-yan-fen-lei-yan-suan-fa/"/>
    <updated>2014-08-08T22:32:18+08:00</updated>
    <id>http://fubuki.github.io/blog/2014/08/08/zi-ran-yu-yan-fen-lei-yan-suan-fa</id>
    <content type="html"><![CDATA[<!-- more -->


<p>紀錄一下在統計自然語言處理的看到的分類演算法。</p>

<ol>
<li>Logistic Regression</li>
<li>Linear Discriminant Analysis</li>
<li>Decision List</li>
<li>Winnow algorithm</li>
<li>Mistake N-Driven Online Linear Threshold Learning Algorithm</li>
<li>Rocchio algorithm</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Explore-Exploit Trade-off]]></title>
    <link href="http://fubuki.github.io/blog/2014/08/04/explore-exploit-trade-off/"/>
    <updated>2014-08-04T23:33:06+08:00</updated>
    <id>http://fubuki.github.io/blog/2014/08/04/explore-exploit-trade-off</id>
    <content type="html"><![CDATA[<!-- more -->


<p><code>We call experimentation  exploration  and we call profit-maximization exploitation</code> 在 Bandit.Algorithms.for.Website.Optimization 書中看到關於 Explore-Exploit trade-off
的定義，簡單來說在解決問題的成本和獲得的利潤上取得平衡，書中開頭的案例:為網站更換 LOGO， 傳統的做法是使用 AB TEST但是花大量的時間，所以從這邊我可以慢慢猜得出來如何跟
Bandit Algorithms 有關。</p>

<p>另外記錄一篇跟<code>Explore-Exploit trade-off</code>相關的有趣論文:<a href="http://research.microsoft.com/apps/pubs/default.aspx?id=122779">Web-Scale Bayesian Click-Through Rate Prediction for Sponsored Search Advertising in Microsoft’s Bing Search Engine</a></p>

<p>另外有幾篇關於A/B Testing 和 Bandit.Algorithms的比較的文章可以作為參考。</p>

<ol>
<li><a href="http://www.chrisstucchio.com/blog/2012/bandit_algorithms_vs_ab.html">Why Multi-armed Bandit Algorithm is Not “Better” than A/B Testing</a></li>
<li><a href="http://stevehanov.ca/blog/index.php?id=132">20 lines of code that will beat A/B testing every time</a></li>
<li><a href="http://www.chrisstucchio.com/blog/2012/bandit_algorithms_vs_ab.html">Why Multi-armed Bandit algorithms are superior to A/B testing</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Multi-armed Bandit Problem]]></title>
    <link href="http://fubuki.github.io/blog/2014/07/30/multi-armed-bandit-problem/"/>
    <updated>2014-07-30T22:55:48+08:00</updated>
    <id>http://fubuki.github.io/blog/2014/07/30/multi-armed-bandit-problem</id>
    <content type="html"><![CDATA[<p>吃角子老虎機問題。</p>

<!-- more -->


<p>在研究 UCT 演算法時有題到 UCB 這個東西，是為了解決<a href="http://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed_bandit</a>類型的問題，要能在多個吃角子老虎機上找出最大收益
，而為了解決這個問題的其中一個演算法就是 UCB 演算法，不過令我注意的是這本書 <code>Bandit Algorithms for Website Optimization</code>這本書，
仔細研究發現這類型的問題也能夠用來優化網站，可以列進下個月的書單了。</p>

<p><a href="https://github.com/johnmyleswhite/BanditsBook">BanditsBook</a> 為 <code>Bandit Algorithms for Website Optimization</code>的範例程式碼。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[圍棋的UCT演算法]]></title>
    <link href="http://fubuki.github.io/blog/2014/07/29/wei-qi-de-uctyan-suan-fa/"/>
    <updated>2014-07-29T23:03:06+08:00</updated>
    <id>http://fubuki.github.io/blog/2014/07/29/wei-qi-de-uctyan-suan-fa</id>
    <content type="html"><![CDATA[<p>在搜尋關於使用統計方法處理自然語言的時候意外看到的東西。</p>

<!-- more -->


<p>以前在大學在上關於人工智慧的課程有提到比起象棋、西洋棋，製作圍棋的人工智慧更困難，
由於可能下的步數太多了導致複雜度比起上述的棋類遊戲還難製作。</p>

<p>到了現在意外看到了UCT演算法，似乎是基於蒙地卡羅法的樹狀搜尋演算法，詳細內容可以參照
<a href="http://en.wikipedia.org/wiki/Monte-Carlo_tree_search">Monte-Carlo_tree_search</a>或是<a href="http://www.game.csie.ndhu.edu.tw/gamewiki/index.php/Monte_Carlo_Tree_Search">Monte_Carlo_Tree_Search</a>，看起來主要是用了Upper Confidence Bounds (UCB)，如果要真正理解就要需要實作一次了。</p>

<p>附註 UCB 演算法 Multi-armed Bandit，   Bandit Algorithms for Website Optimization</p>
]]></content>
  </entry>
  
</feed>
