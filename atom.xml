<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Learning Blog]]></title>
  <link href="http://fubuki.github.io/atom.xml" rel="self"/>
  <link href="http://fubuki.github.io/"/>
  <updated>2015-09-01T23:45:28+08:00</updated>
  <id>http://fubuki.github.io/</id>
  <author>
    <name><![CDATA[Fubuki]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mecab 使用 Wikipedia 增加詞庫]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/01/mecab-wikipedia/"/>
    <updated>2015-09-01T23:36:16+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/01/mecab-wikipedia</id>
    <content type="html"><![CDATA[<!-- more -->


<p>Mecab 可以自行增加詞庫的內容，增加的內容從目前看到的資料有幾個可以使用，主要是要轉換成
Mecab 可以吃的格式，</p>

<ol>
<li>Wikipedia jp</li>
<li>NicoNico</li>
<li>hatenaキーワード</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[語言處理的練習集]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/31/yan-yu-chu-li-100ben-falsetuku-2015/"/>
    <updated>2015-08-31T23:26:04+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/31/yan-yu-chu-li-100ben-falsetuku-2015</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/">言語処理100本ノック 2015</a> 還不錯的練習題目，裡面提到語言處理的基礎概念並且提供了一些練習題，
這些項目在做 NLP 都會遇到可以好好研究。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[建立自己的 Dotfiles]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/30/dotfile/"/>
    <updated>2015-08-30T22:30:11+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/30/dotfile</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://github.com/webpro/awesome-dotfiles">awesome-dotfiles</a></p>

<p><a href="http://qiita.com/b4b4r07/items/b70178e021bef12cd4a2">最強の dotfiles 駆動開発と GitHub で管理する運用方法</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[更換 Lucene Kuromoji 使用的 Dic]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/29/lucene-mecab-kuromoji/"/>
    <updated>2015-08-29T22:37:25+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/29/lucene-mecab-kuromoji</id>
    <content type="html"><![CDATA[<!-- more -->


<p>Lucene 內部是使用 Kuromoji 對日本語做處理，而 Kuromoji 底層是使用 mecab 的  MeCab-IPADIC dictionary，
所以如果要加新詞其實可以透過 mecab 增加詞彙。</p>

<ol>
<li><a href="https://github.com/neologd/mecab-ipadic-neologd">mecab-ipadic-neologd</a></li>
<li><a href="http://d.hatena.ne.jp/Kazuhira/20150316/1426520209">修正されたmecab-ipadic-neologdの辞書を、Lucene Kuromojiに適用してみる</a></li>
<li><a href="http://qiita.com/wakisuke/items/d15b5defc1aad61cc910">mecabの辞書を自動コストで作成</a></li>
<li><a href="http://www.mwsoft.jp/programming/munou/mecab_dic_perform.html">IPA、NAIST、UniDic、JUMANの辞書実演比較</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch Autocomplete 功能]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/28/elassticsearch-suggest/"/>
    <updated>2015-08-28T21:54:13+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/28/elassticsearch-suggest</id>
    <content type="html"><![CDATA[<!-- more -->


<p>elasticsearch 的 suggest 主要分成下面三種</p>

<ol>
<li>Phrase Suggester</li>
<li>Term suggester</li>
<li>Completion Suggester</li>
</ol>


<p>其中 <code>Completion Suggester</code> 目前看起來最適合用來實做 autocomplete 功能，使用上可以搭配  <code>category</code> 可以
增強 autocomplete 的功能，<code>category</code> 能夠自行添加欄位讓開發者可以對資料進行過濾。</p>

<p>目前看起來有幾點要注意:</p>

<ol>
<li>Completion Suggester 可以透過加上 weight 調整排序。</li>
<li>Completion Suggester 有 input 和 output 的欄位，可以讓多個輸入對應到單一輸輸出。</li>
<li>如果有多個 document 相同 output 那 elasticsearch 會只輸出一個。</li>
<li>Category 可以參照 <a href="https://www.elastic.co/blog/elasticsearch-1-2-adding-context-suggestions">Elasticsearch 1.2: Adding Context to Suggestions</a> 裡面有個使用 Category 過濾的例子。</li>
</ol>


<h4>建立 index 和 mapping file</h4>

<h4>加入 document</h4>

<h4>更新 document</h4>

<h4>搜尋</h4>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scala 和 Sbt 的教學]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/27/scala-sbt-jiao-xue/"/>
    <updated>2015-08-27T23:24:16+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/27/scala-sbt-jiao-xue</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://github.com/twitter/scala_school">scala school</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[500px 如何分析資料]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/26/500px-data-analytics/"/>
    <updated>2015-08-26T23:39:02+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/26/500px-data-analytics</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://medium.com/@samson_hu/building-analytics-at-500px-92e9a7005c83">Building Analytics at 500px</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MeCab Analyzer]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/25/mecab-analyzer/"/>
    <updated>2015-08-25T23:14:25+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/25/mecab-analyzer</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://taku910.github.io/mecab/">MeCab</a> 使用 CRF 的日文分析器。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IBM ICU Project]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/24/ibm-icu/"/>
    <updated>2015-08-24T23:36:28+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/24/ibm-icu</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://site.icu-project.org/">ICU - International Components for Unicode</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[資料科學年會 2015 Day 2]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/23/data-science-conf-2015-day-2/"/>
    <updated>2015-08-23T22:00:07+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/23/data-science-conf-2015-day-2</id>
    <content type="html"><![CDATA[<!-- more -->


<h3>Big Education in the Era of Big Data</h3>

<p>Collective Probabilistic Model</p>

<p>我們的教育體制</p>

<p>第一個大資料挑戰 人口普查</p>

<p>講一些泛用的資料處理步驟</p>

<p>資料分析在教育上的應用</p>

<p>Top 10 elearning Statistics</p>

<p>一些線上教育平台</p>

<p>學習精神</p>

<p>MOOCs</p>

<h3>從網頁存取記錄瞭解使用者行為與網頁區塊貢獻分析-實戰篇</h3>

<p>從 access_log 研究 Data driven</p>

<p>log 處理速度</p>

<h4>頁面板塊分析</h4>

<p>必須先統計每個板塊的點擊狀況
統計方式
1. redirect
2. 增加 ref 參數
3.</p>

<p>ref 帶有的資訊
正在哪一頁的哪個版塊和相關資訊</p>

<p>Ref v.1
Ref v.2   如果網站結構改了會有問題吧
Ref v.3</p>

<p>他們有做線上 ABtest?</p>

<p>Google 搜尋 SEO 會有問題</p>

<h4>開始處理 web access log</h4>

<p>為了彌補 GA 沒有的功能</p>

<p>爬蟲很多所以需要過濾</p>

<p>有些必須另外蒐集的資料</p>

<p>這邊使用 Kafka 處理 web access log</p>

<p>clickstream ????</p>

<p>Ref 應該可以完成之前想玩了使用者行為追蹤</p>

<p>強化自己的全文搜尋??? 強化斷詞關係</p>

<p>Ref 的好處</p>

<p>處理 Kafka</p>

<p>Log 儲存 Impala + sql like , PostgreSQL</p>

<p>程式語言 Java</p>

<p>資料整理Excel + Java</p>

<p>RWD 版型怎麼辦 利用 javascript 偵測</p>

<p>跳出率 沒被點擊物品 搜尋優化</p>

<h3>使用 Elasticsearch 及 Kibana 進行巨量資料搜尋及視覺化</h3>

<p>巨量資料怎麼 LOG</p>

<p>資料都是從 mongodb 上匯入的 那會匯入的方式是?</p>

<p>介紹一些內建的資料處理和視覺化方法，果能夠將 access log 匯入
就可以建立一個簡單的監控系統</p>

<p>這邊提到了 Hyperloglog 和 Percentile*  T-digest</p>

<p>gogolook 架構 使用 fluentd</p>

<p>未來可能增加停留時間的記錄</p>

<p>Logstash 比較沒有人在開發所以建議使用 fluentd</p>

<h3>Visualiztion over Web Tools and Tips</h3>

<p>Apple device resolutioins</p>

<p>這邊都是再說 RWD 的設計</p>

<p>不過這邊應該有更多可以考慮的方式</p>

<p>SVG preserveApsectRatio</p>

<p>網頁設計講比較多，因為是要讓資料顯示在網頁上</p>

<p>ai2html</p>

<p>繪圖優化</p>

<p>Cross Device</p>

<p>有些有趣的網站可以參考</p>

<h3>團結力量大？集團企業之解構、分析比較</h3>

<p>這邊主要是利用投資的相關資料畫出相關性。</p>

<h3>社會資訊學？資訊社會學？抑都不是？淺論資訊科學與社會學相得益彰的合作契機</h3>

<p>計算社會學</p>

<p>社會學內容</p>

<p>Agent Based Modeling</p>

<p>資訊科技在社會科學上的應用</p>

<p>有些社會學上的大哉問</p>

<h3>gov</h3>

<ol>
<li>分析蘋果日報的留言 可以看看</li>
<li>判決書非常非常長</li>
<li>新聞品質 量化分析</li>
<li>血庫存量</li>
<li>新台語 運動 台語字典</li>
<li>Data Design</li>
<li>IoT 空汙偵測 DIY</li>
<li>etc</li>
</ol>


<p>詞頻分析</p>

<p>後面有一系列資料，有些可以研究研究</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[資料科學年會 2015 Day 1]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/22/data-science-conf-2015-day-1/"/>
    <updated>2015-08-22T21:51:41+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/22/data-science-conf-2015-day-1</id>
    <content type="html"><![CDATA[<!-- more -->


<h3>為什麼大資料是生死課題？</h3>

<p>大數據的小故事</p>

<p>從 PM 轉資料科學家</p>

<p>這邊主要要了解數據的用途
並且不要拿了鎚子就把每個東西都看成釘子
怎麼使用數據解決問題</p>

<p>數據十誡</p>

<h3>Evolution of Big Data Frameworks</h3>

<p>介紹 Big Data 的生態系統和他們開發的使用工具，有不少使用案例</p>

<p>graph middleware</p>

<p>putting the price on social connection</p>

<p>從資料推測這個人是否會犯罪</p>

<p>Big Data Analytics Resource</p>

<p>回去看看他提供的在線資源</p>

<h3>運用空間決策改進緊急醫療品質</h3>

<p>GIS 系統
大概是繪製醫院的地理地圖然後預測要送到哪個醫院
這邊大概先將醫院的點放在地圖然後透過演算法取得最好的位置。</p>

<h3>以健保資料分析對抗健康新聞的恐慌症候群</h3>

<p>mysql 匯入資料</p>

<p>健保資料是單純的文字檔需要透過已經設定好了 schema 重新處理
相關的資料。</p>

<p>ICD-9-CM</p>

<p>我覺得這類是屬於 Bad-data 的領域</p>

<p>沒有特別的使用方式</p>

<p>這邊應該多講點有哪些骯髒的資料格式然後需要怎麼處理
有沒有其他好用的工具可以自動修正這類的問題這樣比較好玩</p>

<h3>人口統計應用於選舉預測</h3>

<p>Generalized Linear Model</p>

<p>貝氏機率</p>

<h3>由點、線至面：從影像分析角度探討漫畫的組成與風格</h3>

<p>主要是研究日本漫畫</p>

<p>這不是死神嗎XDD
1. Drawing
2. Language
3. Panel</p>

<p>SCREENTONE detection</p>

<p>character detection 不能用普通的人臉偵測</p>

<p>Line Feature Extration</p>

<p>Feature Analysis</p>

<p>六種線段特徵有些特徵不太用</p>

<p>漫畫家師徒關係</p>

<p>重點來了</p>

<p>Syle-Based Art Movement Retrieval</p>

<p>Syle-Based Art Retrieval</p>

<p>JOJO 冒險野郎</p>

<p>Artwork Period Retrieval</p>

<p>找尋畫家特定時期畫風</p>

<p>畫家風格的影響</p>

<p>Part2 Comics-Based Storytelling</p>

<p>將有時間序列關係的片段轉成影片</p>

<p>Challenges</p>

<p>有三個問題要解決</p>

<p>labeling problem</p>

<p>Balloon Placement</p>

<p>particle swarm optimization</p>

<h3>心理學x資料科學</h3>

<ol>
<li>人類行為的量化分析</li>
<li>巨量實驗的必要性</li>
<li>開放腦資料的挑戰</li>
</ol>


<p>你的潛意識存在著資訊焦慮</p>

<p>不知在讀研究報告還是科幻小說</p>

<p>對國家未來的正面言談是經濟的反指標</p>

<p>地區性心臟病死亡率可由 Tweets 預測</p>

<p>天氣影響生活滿意度的評估</p>

<p>體感影響社會判斷與社交行為</p>

<p>商店背景音樂影響買酒的選擇  ???</p>

<p>候選人的外貌影響選舉的結果</p>

<p>男性偏好紅色衣著的女性</p>

<p>上吊自殺 vs. 科學經費</p>

<p>Grasp and lift egg detection</p>

<p>大資料神經科學</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GopherCon 2015]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/21/gophercon-2015/"/>
    <updated>2015-08-21T22:24:21+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/21/gophercon-2015</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://www.gophercon.com/">GopherCon 2015</a></p>

<p><a href="https://github.com/gophercon/2015-talks">2015-talks</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PHP 的 Pcntl_fork 函式]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/20/php-pcntl-fork/"/>
    <updated>2015-08-20T23:18:11+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/20/php-pcntl-fork</id>
    <content type="html"><![CDATA[<!-- more -->


<p>最近在使用 PHP 撰寫 CLI 的功能時，想要實做能夠根據 CPU 數量自動 auto scale 加快計算的功能，
所以在尋找 PHP 裡面跟 fork 有關的函式，最後找到了 pcntl_fork 這個函式能夠 fork 出多個 process ，
使用上不太難不過子進程結束需要自行。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ontology Ranking Algorithm]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/19/ontology-score/"/>
    <updated>2015-08-19T22:50:08+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/19/ontology-score</id>
    <content type="html"><![CDATA[<!-- more -->


<p>一些文件的排序演算法，用來算出文件的相關性。</p>

<ol>
<li>Class Match Measure</li>
<li>Density Measure</li>
<li>Semantic Similarity Measure</li>
<li>Betweenness Measure</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[處理大型數據集的方法]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/18/mining-of-massive-datasets/"/>
    <updated>2015-08-18T23:50:36+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/18/mining-of-massive-datasets</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://www.mmds.org/">Mining of Massive Datasets</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OTR vs PGP 加密]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/17/otr-vs-pgp/"/>
    <updated>2015-08-17T23:21:01+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/17/otr-vs-pgp</id>
    <content type="html"><![CDATA[<!-- more -->


<p><code>Off-the-Record Communication, or, Why Not To Use PGP</code> 兩種加密協議的比較，之前在聽關於使用
xmpp 協定跟別人聊天的 workshop，裡面提到了 OTR 跟 PGP 這兩種加密方式，不過經過研究 PGP 加密有些問題，
比較推薦使用 OTR，。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Coscup 2015 Day2]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/16/coscup-2015-day2/"/>
    <updated>2015-08-16T20:02:47+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/16/coscup-2015-day2</id>
    <content type="html"><![CDATA[<!-- more -->


<h3>How Redis Powers Your Web Service &amp; Flurry analytics Intro</h3>

<p>Yahoo APAC Data Team</p>

<p>Yahoo Redis 是怎麼使用的</p>

<ol>
<li>Sentinel</li>
<li>twemproxy</li>
<li>redis cluster</li>
</ol>


<p>幾乎以前就聽過了</p>

<h4>Flurry Analytics (Yahoo mobile developer suite)</h4>

<p>手機資料分析工具</p>

<h3>Personalized Search in Yahoo Taiwan eCommerce Sites</h3>

<ol>
<li>搜尋經驗優化</li>
<li>個人化搜尋</li>
<li>演算法和資料量</li>
<li>使用哪些開源工具</li>
</ol>


<p>重要是 machine learning ranking 應該就是</p>

<p>機器學習用哪個算法
資料集怎麼來的</p>

<p>商品了解</p>

<p>重要產品標籤辨識
LDA SVM</p>

<p>重要產品</p>

<p>使用者偏好推定</p>

<p>巨量資料跟即時運算的問題</p>

<p>PIG 的用法</p>

<p>PLSI EM algorithm</p>

<p>mahout => spark MLlib</p>

<p>K-means</p>

<p>spark 可以加速運算</p>

<p>Logistic Regression</p>

<p>decision tree
使用 Random forest  加快</p>

<p>使用者短期行為處理</p>

<p>Storm</p>

<h3>Neural Turing Machines Implementation</h3>

<p>HMM => Speech recognition</p>

<p>SVM => Image recogniton</p>

<p>CNN</p>

<p>RNN</p>

<p>=> Neural Turing Machine</p>

<p>新的論文可以看看</p>

<h3>堆疊之下</h3>

<p>有做 information retrival</p>

<ol>
<li><p>Data-Driven 資料導向</p>

<ul>
<li>A/B testing</li>
<li>MAB testing</li>
</ul>
</li>
<li><p>Dev Ops 分工</p></li>
<li><p>IT部門 ~900 人,小隊伍 (6人)</p></li>
</ol>


<p>主要講 Booking 的背後使用哪些語言跟軟體</p>

<h3>自己的機器人自己做</h3>

<p>使用 arduino 製作機器人</p>

<p>目前尚未完成</p>

<h3>從UAV到UAS 開源無人機的技術與下一步</h3>

<p>AHRS 系統跟多軸飛行器使用的組件跟用途</p>

<h3>「封麥」演說：台灣開放原始碼生態圈回顧</h3>

<h3>Lightning Talk</h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Coscup 2015 Day1]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/15/coscup-2015-day1/"/>
    <updated>2015-08-15T22:09:54+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/15/coscup-2015-day1</id>
    <content type="html"><![CDATA[<!-- more -->


<h3>BYOC: Build Your Own COSCUP</h3>

<p>介紹 coscup 從以前到現在的演進跟內部怎麼分工</p>

<h3>中文排版需求以及我在W3C看到的事情</h3>

<p>中文排版需求第一份使用中文撰寫文檔</p>

<p>講解 epub 演進的歷史
假裝一切都做好了是最麻煩的</p>

<p>中文排版規格挖坑</p>

<p>UA Stylesheet 導致中文排版問題的元兇</p>

<p>Round Display 給圓形螢幕使用的  CSS</p>

<p><code>light-level</code>  為 media query 的屬性可以根據光源調整 css</p>

<p>CSS SECRETS 一本書可以看看</p>

<p>Text-wrap :balance</p>

<p>CSS scrollbar 微軟提出的用來實做常見的捲動效果</p>

<h3>PIME - 用 &ldquo;Python&rdquo; 快速開發 Windows 的中文輸入法</h3>

<p>看到 PCMAN 本人</p>

<p>講解了 windows 上面輸入法的差別，基本上分成兩種在加上 32 位元跟 64 位元所以會有四種情形。</p>

<p>Demo 了喵喵輸入法</p>

<p>主要是使用了 Client-Server 的架構，所以只要更改 Server 的程式便可以快速修改輸入法的功能。</p>

<h3>Linux 桌面系統在繁體中文資訊化的發展回顧</h3>

<p>這場主要是講 Linux 跟一些應用軟體的中文化情形，太少人參與軟體中文化，應該說
以前的使用者會回饋一些 patch 回來，不過現在</p>

<p>CLE</p>

<p>CLDP</p>

<h3>workshop</h3>

<p>跑去參加 xmpp 的 workshop，這場收穫比較大的是修正一些以前對於 xmpp 的錯誤概念，
之後實做聊天軟體時可以參考看看。</p>

<h3>A Fresh Look at Accessibility (on the web and mobile devices)</h3>

<p>無障礙網路空間</p>

<p>講一些目前 w3c 的規範</p>

<h3>第一次自幹 Open Data SimCity 就上手</h3>

<p>google map + d3.js 實做資料視覺化</p>

<p>主要在 Demo 效果。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Splainer : Explain Solr Result]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/14/splainer/"/>
    <updated>2015-08-14T22:52:43+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/14/splainer</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://github.com/o19s/splainer">splainer</a> 是可以利用 solr 的搜尋結果分析背後的分數，跟使用 Lucene 的 explain api 得出背後的得分類似。
。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[針對短文本做語言偵測]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/13/short-text-language-detect/"/>
    <updated>2015-08-13T21:08:49+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/13/short-text-language-detect</id>
    <content type="html"><![CDATA[<!-- more -->


<p>針對類似 <code>tweet</code> 的短文本進行語言偵測。以前有用過 Tika 實做語言偵測不過命中率從別人的測試數據看起來不太好，
之後從別的地方聽到了 <a href="https://github.com/CLD2Owners/cld2">cld2</a> 效果會比較好，不過在對很文本長度不長情形下準度會下降，所以另外研究了 <a href="http://www.slideshare.net/shuyo/short-text-language-detection-with-infinitygram-12949447">Short Text Language Detection with Infinity-Gram</a>
使用其他方法嘗試解決這類的問題。</p>
]]></content>
  </entry>
  
</feed>
