<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Learning Blog]]></title>
  <link href="http://fubuki.github.io/atom.xml" rel="self"/>
  <link href="http://fubuki.github.io/"/>
  <updated>2015-09-06T23:05:35+08:00</updated>
  <id>http://fubuki.github.io/</id>
  <author>
    <name><![CDATA[Fubuki]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[NPYLM 和 HPYLM]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/06/npylm/"/>
    <updated>2015-09-06T22:40:48+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/06/npylm</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://www.youtube.com/watch?v=GrTgJi65-Mg">理論はどうでもいいから作ってみたい人のためのNPYLM + 実装のための解説</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用 Stream2es 匯入 Wikipedia 資料]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/05/elasticsearch-wikipedia-stream2es/"/>
    <updated>2015-09-05T23:38:48+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/05/elasticsearch-wikipedia-stream2es</id>
    <content type="html"><![CDATA[<!-- more -->


<p>目前手上已經有一些 Wikipedia 的資料，這是之前在使用 nlp4l 做為輸入資料遺留下來的，
那時使用了 json-wikipedia 將 xml 轉換成 json ，使用 jq 看過一遍大致上了解了內容的
資料結構，不過由於資料太過於龐大搜尋起來很久，所以使用了之前看到的工具 stream2es 將
手上的資料轉換到 elasticsearch 裡面。</p>

<p>最後轉換的結果有點少，只有一百九十萬多筆，有些資料似乎沒有匯入進去，之後要換用 Logstash
 匯入應該會有不一樣的結果。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Wikipedia Dump Data 解析]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/04/wikipedia-analysis/"/>
    <updated>2015-09-04T23:47:53+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/04/wikipedia-analysis</id>
    <content type="html"><![CDATA[<!-- more -->


<p>預定之後要處理 <a href="http://www.slideshare.net/ghazel7/wikipedia-17666978">Wikipedia解析</a> 的事情。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 適合的 Shard Size]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/03/elasticsearch-shard-size/"/>
    <updated>2015-09-03T23:12:17+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/03/elasticsearch-shard-size</id>
    <content type="html"><![CDATA[<!-- more -->


<p>最近在思考 elasticsearch 優化的部分，當 index 不斷擴大的時候怎麼處理，目前是想到將資料做
 shard 然後使用多個 node 加快搜尋的速度，但是這邊有個問題是每個 shard 的大小要怎麼決定，
 這邊就暫時參考 <a href="http://engineering.datarank.com/2015/07/08/balancing-elasticsearch-cluster-by-shard-size.html">Balancing an Elasticsearch Cluster by Shard Size</a> 裡面提到的指標和工具測試看看。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Doc2Vec 相關]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/02/doc2vec-papper/"/>
    <updated>2015-09-02T23:28:43+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/02/doc2vec-papper</id>
    <content type="html"><![CDATA[<!-- more -->


<p>之前已經在 python 上玩過 word vectors ，而最近看到一篇關於 paragraph vector 的論文 <a href="http://arxiv.org/abs/1405.4053">Distributed Representations of Sentences and Documents</a>
需要了解一下差別和用途， <a href="https://github.com/mesnilgr/iclr15">iclr15</a> 則是另外一篇跟 <code>paragraph vector</code> 相關論文裡的程式碼，可以嘗試看看有沒有達成論文中的效果。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mecab 使用 Wikipedia 增加詞庫]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/01/mecab-wikipedia/"/>
    <updated>2015-09-01T23:36:16+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/01/mecab-wikipedia</id>
    <content type="html"><![CDATA[<!-- more -->


<p>Mecab 可以自行增加詞庫的內容，增加的內容從目前看到的資料有幾個可以使用，主要是要轉換成
Mecab 可以吃的格式，</p>

<ol>
<li>Wikipedia jp</li>
<li>NicoNico</li>
<li>hatenaキーワード</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[語言處理的練習集]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/31/yan-yu-chu-li-100ben-falsetuku-2015/"/>
    <updated>2015-08-31T23:26:04+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/31/yan-yu-chu-li-100ben-falsetuku-2015</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/">言語処理100本ノック 2015</a> 還不錯的練習題目，裡面提到語言處理的基礎概念並且提供了一些練習題，
這些項目在做 NLP 都會遇到可以好好研究。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[建立自己的 Dotfiles]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/30/dotfile/"/>
    <updated>2015-08-30T22:30:11+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/30/dotfile</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://github.com/webpro/awesome-dotfiles">awesome-dotfiles</a></p>

<p><a href="http://qiita.com/b4b4r07/items/b70178e021bef12cd4a2">最強の dotfiles 駆動開発と GitHub で管理する運用方法</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[更換 Lucene Kuromoji 使用的 Dic]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/29/lucene-mecab-kuromoji/"/>
    <updated>2015-08-29T22:37:25+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/29/lucene-mecab-kuromoji</id>
    <content type="html"><![CDATA[<!-- more -->


<p>Lucene 內部是使用 Kuromoji 對日本語做處理，而 Kuromoji 底層是使用 mecab 的  MeCab-IPADIC dictionary，
所以如果要加新詞其實可以透過 mecab 增加詞彙。</p>

<ol>
<li><a href="https://github.com/neologd/mecab-ipadic-neologd">mecab-ipadic-neologd</a></li>
<li><a href="http://d.hatena.ne.jp/Kazuhira/20150316/1426520209">修正されたmecab-ipadic-neologdの辞書を、Lucene Kuromojiに適用してみる</a></li>
<li><a href="http://qiita.com/wakisuke/items/d15b5defc1aad61cc910">mecabの辞書を自動コストで作成</a></li>
<li><a href="http://www.mwsoft.jp/programming/munou/mecab_dic_perform.html">IPA、NAIST、UniDic、JUMANの辞書実演比較</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch Autocomplete 功能]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/28/elassticsearch-suggest/"/>
    <updated>2015-08-28T21:54:13+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/28/elassticsearch-suggest</id>
    <content type="html"><![CDATA[<!-- more -->


<p>elasticsearch 的 suggest 主要分成下面三種</p>

<ol>
<li>Phrase Suggester</li>
<li>Term suggester</li>
<li>Completion Suggester</li>
</ol>


<p>其中 <code>Completion Suggester</code> 目前看起來最適合用來實做 autocomplete 功能，使用上可以搭配  <code>category</code> 可以
增強 autocomplete 的功能，<code>category</code> 能夠自行添加欄位讓開發者可以對資料進行過濾。</p>

<p>目前看起來有幾點要注意:</p>

<ol>
<li>Completion Suggester 可以透過加上 weight 調整排序。</li>
<li>Completion Suggester 有 input 和 output 的欄位，可以讓多個輸入對應到單一輸輸出。</li>
<li>如果有多個 document 相同 output 那 elasticsearch 會只輸出一個。</li>
<li>Category 可以參照 <a href="https://www.elastic.co/blog/elasticsearch-1-2-adding-context-suggestions">Elasticsearch 1.2: Adding Context to Suggestions</a> 裡面有個使用 Category 過濾的例子。</li>
</ol>


<h4>建立 index 和 mapping file</h4>

<h4>加入 document</h4>

<h4>更新 document</h4>

<h4>搜尋</h4>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scala 和 Sbt 的教學]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/27/scala-sbt-jiao-xue/"/>
    <updated>2015-08-27T23:24:16+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/27/scala-sbt-jiao-xue</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://github.com/twitter/scala_school">scala school</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[500px 如何分析資料]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/26/500px-data-analytics/"/>
    <updated>2015-08-26T23:39:02+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/26/500px-data-analytics</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://medium.com/@samson_hu/building-analytics-at-500px-92e9a7005c83">Building Analytics at 500px</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MeCab Analyzer]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/25/mecab-analyzer/"/>
    <updated>2015-08-25T23:14:25+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/25/mecab-analyzer</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://taku910.github.io/mecab/">MeCab</a> 使用 CRF 的日文分析器。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IBM ICU Project]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/24/ibm-icu/"/>
    <updated>2015-08-24T23:36:28+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/24/ibm-icu</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://site.icu-project.org/">ICU - International Components for Unicode</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[資料科學年會 2015 Day 2]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/23/data-science-conf-2015-day-2/"/>
    <updated>2015-08-23T22:00:07+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/23/data-science-conf-2015-day-2</id>
    <content type="html"><![CDATA[<!-- more -->


<h3>Big Education in the Era of Big Data</h3>

<p>Collective Probabilistic Model</p>

<p>我們的教育體制</p>

<p>第一個大資料挑戰 人口普查</p>

<p>講一些泛用的資料處理步驟</p>

<p>資料分析在教育上的應用</p>

<p>Top 10 elearning Statistics</p>

<p>一些線上教育平台</p>

<p>學習精神</p>

<p>MOOCs</p>

<h3>從網頁存取記錄瞭解使用者行為與網頁區塊貢獻分析-實戰篇</h3>

<p>從 access_log 研究 Data driven</p>

<p>log 處理速度</p>

<h4>頁面板塊分析</h4>

<p>必須先統計每個板塊的點擊狀況
統計方式
1. redirect
2. 增加 ref 參數
3.</p>

<p>ref 帶有的資訊
正在哪一頁的哪個版塊和相關資訊</p>

<p>Ref v.1
Ref v.2   如果網站結構改了會有問題吧
Ref v.3</p>

<p>他們有做線上 ABtest?</p>

<p>Google 搜尋 SEO 會有問題</p>

<h4>開始處理 web access log</h4>

<p>為了彌補 GA 沒有的功能</p>

<p>爬蟲很多所以需要過濾</p>

<p>有些必須另外蒐集的資料</p>

<p>這邊使用 Kafka 處理 web access log</p>

<p>clickstream ????</p>

<p>Ref 應該可以完成之前想玩了使用者行為追蹤</p>

<p>強化自己的全文搜尋??? 強化斷詞關係</p>

<p>Ref 的好處</p>

<p>處理 Kafka</p>

<p>Log 儲存 Impala + sql like , PostgreSQL</p>

<p>程式語言 Java</p>

<p>資料整理Excel + Java</p>

<p>RWD 版型怎麼辦 利用 javascript 偵測</p>

<p>跳出率 沒被點擊物品 搜尋優化</p>

<h3>使用 Elasticsearch 及 Kibana 進行巨量資料搜尋及視覺化</h3>

<p>巨量資料怎麼 LOG</p>

<p>資料都是從 mongodb 上匯入的 那會匯入的方式是?</p>

<p>介紹一些內建的資料處理和視覺化方法，果能夠將 access log 匯入
就可以建立一個簡單的監控系統</p>

<p>這邊提到了 Hyperloglog 和 Percentile*  T-digest</p>

<p>gogolook 架構 使用 fluentd</p>

<p>未來可能增加停留時間的記錄</p>

<p>Logstash 比較沒有人在開發所以建議使用 fluentd</p>

<h3>Visualiztion over Web Tools and Tips</h3>

<p>Apple device resolutioins</p>

<p>這邊都是再說 RWD 的設計</p>

<p>不過這邊應該有更多可以考慮的方式</p>

<p>SVG preserveApsectRatio</p>

<p>網頁設計講比較多，因為是要讓資料顯示在網頁上</p>

<p>ai2html</p>

<p>繪圖優化</p>

<p>Cross Device</p>

<p>有些有趣的網站可以參考</p>

<h3>團結力量大？集團企業之解構、分析比較</h3>

<p>這邊主要是利用投資的相關資料畫出相關性。</p>

<h3>社會資訊學？資訊社會學？抑都不是？淺論資訊科學與社會學相得益彰的合作契機</h3>

<p>計算社會學</p>

<p>社會學內容</p>

<p>Agent Based Modeling</p>

<p>資訊科技在社會科學上的應用</p>

<p>有些社會學上的大哉問</p>

<h3>gov</h3>

<ol>
<li>分析蘋果日報的留言 可以看看</li>
<li>判決書非常非常長</li>
<li>新聞品質 量化分析</li>
<li>血庫存量</li>
<li>新台語 運動 台語字典</li>
<li>Data Design</li>
<li>IoT 空汙偵測 DIY</li>
<li>etc</li>
</ol>


<p>詞頻分析</p>

<p>後面有一系列資料，有些可以研究研究</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[資料科學年會 2015 Day 1]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/22/data-science-conf-2015-day-1/"/>
    <updated>2015-08-22T21:51:41+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/22/data-science-conf-2015-day-1</id>
    <content type="html"><![CDATA[<!-- more -->


<h3>為什麼大資料是生死課題？</h3>

<p>大數據的小故事</p>

<p>從 PM 轉資料科學家</p>

<p>這邊主要要了解數據的用途
並且不要拿了鎚子就把每個東西都看成釘子
怎麼使用數據解決問題</p>

<p>數據十誡</p>

<h3>Evolution of Big Data Frameworks</h3>

<p>介紹 Big Data 的生態系統和他們開發的使用工具，有不少使用案例</p>

<p>graph middleware</p>

<p>putting the price on social connection</p>

<p>從資料推測這個人是否會犯罪</p>

<p>Big Data Analytics Resource</p>

<p>回去看看他提供的在線資源</p>

<h3>運用空間決策改進緊急醫療品質</h3>

<p>GIS 系統
大概是繪製醫院的地理地圖然後預測要送到哪個醫院
這邊大概先將醫院的點放在地圖然後透過演算法取得最好的位置。</p>

<h3>以健保資料分析對抗健康新聞的恐慌症候群</h3>

<p>mysql 匯入資料</p>

<p>健保資料是單純的文字檔需要透過已經設定好了 schema 重新處理
相關的資料。</p>

<p>ICD-9-CM</p>

<p>我覺得這類是屬於 Bad-data 的領域</p>

<p>沒有特別的使用方式</p>

<p>這邊應該多講點有哪些骯髒的資料格式然後需要怎麼處理
有沒有其他好用的工具可以自動修正這類的問題這樣比較好玩</p>

<h3>人口統計應用於選舉預測</h3>

<p>Generalized Linear Model</p>

<p>貝氏機率</p>

<h3>由點、線至面：從影像分析角度探討漫畫的組成與風格</h3>

<p>主要是研究日本漫畫</p>

<p>這不是死神嗎XDD
1. Drawing
2. Language
3. Panel</p>

<p>SCREENTONE detection</p>

<p>character detection 不能用普通的人臉偵測</p>

<p>Line Feature Extration</p>

<p>Feature Analysis</p>

<p>六種線段特徵有些特徵不太用</p>

<p>漫畫家師徒關係</p>

<p>重點來了</p>

<p>Syle-Based Art Movement Retrieval</p>

<p>Syle-Based Art Retrieval</p>

<p>JOJO 冒險野郎</p>

<p>Artwork Period Retrieval</p>

<p>找尋畫家特定時期畫風</p>

<p>畫家風格的影響</p>

<p>Part2 Comics-Based Storytelling</p>

<p>將有時間序列關係的片段轉成影片</p>

<p>Challenges</p>

<p>有三個問題要解決</p>

<p>labeling problem</p>

<p>Balloon Placement</p>

<p>particle swarm optimization</p>

<h3>心理學x資料科學</h3>

<ol>
<li>人類行為的量化分析</li>
<li>巨量實驗的必要性</li>
<li>開放腦資料的挑戰</li>
</ol>


<p>你的潛意識存在著資訊焦慮</p>

<p>不知在讀研究報告還是科幻小說</p>

<p>對國家未來的正面言談是經濟的反指標</p>

<p>地區性心臟病死亡率可由 Tweets 預測</p>

<p>天氣影響生活滿意度的評估</p>

<p>體感影響社會判斷與社交行為</p>

<p>商店背景音樂影響買酒的選擇  ???</p>

<p>候選人的外貌影響選舉的結果</p>

<p>男性偏好紅色衣著的女性</p>

<p>上吊自殺 vs. 科學經費</p>

<p>Grasp and lift egg detection</p>

<p>大資料神經科學</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GopherCon 2015]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/21/gophercon-2015/"/>
    <updated>2015-08-21T22:24:21+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/21/gophercon-2015</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://www.gophercon.com/">GopherCon 2015</a></p>

<p><a href="https://github.com/gophercon/2015-talks">2015-talks</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PHP 的 Pcntl_fork 函式]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/20/php-pcntl-fork/"/>
    <updated>2015-08-20T23:18:11+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/20/php-pcntl-fork</id>
    <content type="html"><![CDATA[<!-- more -->


<p>最近在使用 PHP 撰寫 CLI 的功能時，想要實做能夠根據 CPU 數量自動 auto scale 加快計算的功能，
所以在尋找 PHP 裡面跟 fork 有關的函式，最後找到了 pcntl_fork 這個函式能夠 fork 出多個 process ，
使用上不太難不過子進程結束需要自行。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ontology Ranking Algorithm]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/19/ontology-score/"/>
    <updated>2015-08-19T22:50:08+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/19/ontology-score</id>
    <content type="html"><![CDATA[<!-- more -->


<p>一些文件的排序演算法，用來算出文件的相關性。</p>

<ol>
<li>Class Match Measure</li>
<li>Density Measure</li>
<li>Semantic Similarity Measure</li>
<li>Betweenness Measure</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[處理大型數據集的方法]]></title>
    <link href="http://fubuki.github.io/blog/2015/08/18/mining-of-massive-datasets/"/>
    <updated>2015-08-18T23:50:36+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/08/18/mining-of-massive-datasets</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://www.mmds.org/">Mining of Massive Datasets</a></p>
]]></content>
  </entry>
  
</feed>
