<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Learning Blog]]></title>
  <link href="http://fubuki.github.io/atom.xml" rel="self"/>
  <link href="http://fubuki.github.io/"/>
  <updated>2015-09-21T23:42:18+08:00</updated>
  <id>http://fubuki.github.io/</id>
  <author>
    <name><![CDATA[Fubuki]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[將資料從 Postgres 同步到 Elasticsearch]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/21/syncing-postgres-to-elasticsearch-lessons-learned/"/>
    <updated>2015-09-21T23:40:11+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/21/syncing-postgres-to-elasticsearch-lessons-learned</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://gocardless.com/blog/syncing-postgres-to-elasticsearch-lessons-learned/">Syncing Postgres to Elasticsearch: lessons learned</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lightning Memory-Mapped Database]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/20/lightning-memory-mapped-database/"/>
    <updated>2015-09-20T21:53:08+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/20/lightning-memory-mapped-database</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://en.wikipedia.org/wiki/Lightning_Memory-Mapped_Database">Lightning Memory-Mapped Database</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GloVe]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/19/glove/"/>
    <updated>2015-09-19T23:20:59+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/19/glove</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://nlp.stanford.edu/projects/glove/">GloVe: Global Vectors for Word Representation</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Factorization Machines]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/18/factorization-machines/"/>
    <updated>2015-09-18T23:37:16+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/18/factorization-machines</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://libfm.org/">libFM: Factorization Machine Library</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 的 Aggregations 功能]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/17/elasticsearch-aggregations/"/>
    <updated>2015-09-17T00:24:18+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/17/elasticsearch-aggregations</id>
    <content type="html"><![CDATA[<!-- more -->


<p>elasticsearch  使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html#search-aggregations">Aggregations</a> 取代 facted。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[關於 Full Stack Developer 的存在]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/16/the-full-stack-developer-is-a-myth/"/>
    <updated>2015-09-16T23:09:06+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/16/the-full-stack-developer-is-a-myth</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://blog.growth.supply/the-full-stack-developer-is-a-myth-4e3fb9c25867">The full stack developer is a myth</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用 Lucene Index Data 建立 Word2vec 的資料]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/15/word2vec-for-lucene/"/>
    <updated>2015-09-15T23:37:33+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/15/word2vec-for-lucene</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://lucene.jugem.jp/?eid=479">word2vec for Lucene</a> 使用 Lucene 的索引建立 word2vec 的資料。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MLDM Monday --- 中文搜尋經驗分享]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/14/mldm-monday-zhong-wen-sou-xun-jing-yan-fen-xiang/"/>
    <updated>2015-09-14T23:26:59+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/14/mldm-monday-zhong-wen-sou-xun-jing-yan-fen-xiang</id>
    <content type="html"><![CDATA[<!-- more -->


<p>今天去參加一場 Meetup 內容是 <a href="http://blog.liang2.tw/2015Talk-Chinese-Search/#cover">中文搜尋經驗分享</a>，主要是講 Pinkoi 怎麼使用 elasticsearch 建立電商搜尋服務。</p>

<p>內容是先簡介一下 elasticearch 然後解說怎麼使用  jieba ，並且使用一些繁體中文資源建立 jieba 分詞用的詞典，
這邊是使用 wikipedia 和萌典，不過由於 jieba 是中國大陸那邊開發的所以有些訓練出來的模型像是 HMM 是針對簡體中文，
需要另外重新訓練或是處理。</p>

<p>最後就是介紹 word2vec，使用斷詞過的 wikipedia + gensim 建立資料，這是為了處理使用者搜尋不到的情形，找尋相關的關鍵字。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fish-shell]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/13/fish-shell/"/>
    <updated>2015-09-13T21:53:01+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/13/fish-shell</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://github.com/fish-shell/fish-shell">fish-shell</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Word2vec 建立本體模型]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/12/word2vec/"/>
    <updated>2015-09-12T23:41:44+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/12/word2vec</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://github.com/piskvorky/gensim/">gensim</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[顯示 Mecab 分詞的方式]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/11/n-best-search-algorithm/"/>
    <updated>2015-09-11T22:48:43+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/11/n-best-search-algorithm</id>
    <content type="html"><![CDATA[<!-- more -->


<ol>
<li><a href="http://d.hatena.ne.jp/a_bicky/20150413/1428872753">MeCab で N-Best 解の累積コストを出力する</a></li>
<li><a href="http://www.mwsoft.jp/programming/munou/mecab_nitteretou.html">日本テレビ東京で学ぶMeCabのコスト計算</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Count–min Sketch Algorithm]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/10/count-min-sketch-algorithm/"/>
    <updated>2015-09-10T23:40:34+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/10/count-min-sketch-algorithm</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch">Count–min sketch</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LTP: Language Technology Platform]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/09/ltp-language-technology-platform/"/>
    <updated>2015-09-09T23:05:41+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/09/ltp-language-technology-platform</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://github.com/HIT-SCIR/ltp">ltp</a> 哈爾濱工業大學(哈工大)提供的中文自然語言處理平台，之前有看到哈工大有一提供
一個線上的版本給人使用，而這個 <a href="https://github.com/HIT-SCIR/ltp">ltp</a> 應該就是提供給別人自行研究擴展的版本。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kagome 分詞器]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/08/kagome/"/>
    <updated>2015-09-08T23:36:54+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/08/kagome</id>
    <content type="html"><![CDATA[<!-- more -->


<ol>
<li><a href="https://github.com/ikawaha/kagome">kagome</a></li>
<li><a href="http://qiita.com/ikawaha/items/ff27ac03e22b7f36811b">Pure Go で辞書同梱な形態素解析器 kagome を公開してみました</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PHP 處理 Unicode 字元]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/07/php-regexp-unicode/"/>
    <updated>2015-09-07T23:06:35+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/07/php-regexp-unicode</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="http://php.net/manual/en/regexp.reference.unicode.php">Unicode character properties</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NPYLM 和 HPYLM]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/06/npylm/"/>
    <updated>2015-09-06T22:40:48+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/06/npylm</id>
    <content type="html"><![CDATA[<!-- more -->


<p><a href="https://www.youtube.com/watch?v=GrTgJi65-Mg">理論はどうでもいいから作ってみたい人のためのNPYLM + 実装のための解説</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用 Stream2es 匯入 Wikipedia 資料]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/05/elasticsearch-wikipedia-stream2es/"/>
    <updated>2015-09-05T23:38:48+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/05/elasticsearch-wikipedia-stream2es</id>
    <content type="html"><![CDATA[<!-- more -->


<p>目前手上已經有一些 Wikipedia 的資料，這是之前在使用 nlp4l 做為輸入資料遺留下來的，
那時使用了 json-wikipedia 將 xml 轉換成 json ，使用 jq 看過一遍大致上了解了內容的
資料結構，不過由於資料太過於龐大搜尋起來很久，所以使用了之前看到的工具 stream2es 將
手上的資料轉換到 elasticsearch 裡面。</p>

<p>最後轉換的結果有點少，只有一百九十萬多筆，有些資料似乎沒有匯入進去，之後要換用 Logstash
 匯入應該會有不一樣的結果。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Wikipedia Dump Data 解析]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/04/wikipedia-analysis/"/>
    <updated>2015-09-04T23:47:53+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/04/wikipedia-analysis</id>
    <content type="html"><![CDATA[<!-- more -->


<p>預定之後要處理 <a href="http://www.slideshare.net/ghazel7/wikipedia-17666978">Wikipedia解析</a> 的事情。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch 適合的 Shard Size]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/03/elasticsearch-shard-size/"/>
    <updated>2015-09-03T23:12:17+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/03/elasticsearch-shard-size</id>
    <content type="html"><![CDATA[<!-- more -->


<p>最近在思考 elasticsearch 優化的部分，當 index 不斷擴大的時候怎麼處理，目前是想到將資料做
 shard 然後使用多個 node 加快搜尋的速度，但是這邊有個問題是每個 shard 的大小要怎麼決定，
 這邊就暫時參考 <a href="http://engineering.datarank.com/2015/07/08/balancing-elasticsearch-cluster-by-shard-size.html">Balancing an Elasticsearch Cluster by Shard Size</a> 裡面提到的指標和工具測試看看。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Doc2Vec 相關]]></title>
    <link href="http://fubuki.github.io/blog/2015/09/02/doc2vec-papper/"/>
    <updated>2015-09-02T23:28:43+08:00</updated>
    <id>http://fubuki.github.io/blog/2015/09/02/doc2vec-papper</id>
    <content type="html"><![CDATA[<!-- more -->


<p>之前已經在 python 上玩過 word vectors ，而最近看到一篇關於 paragraph vector 的論文 <a href="http://arxiv.org/abs/1405.4053">Distributed Representations of Sentences and Documents</a>
需要了解一下差別和用途， <a href="https://github.com/mesnilgr/iclr15">iclr15</a> 則是另外一篇跟 <code>paragraph vector</code> 相關論文裡的程式碼，可以嘗試看看有沒有達成論文中的效果。</p>
]]></content>
  </entry>
  
</feed>
